{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012aaf0-b5b0-4c66-b718-75369ce08718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe modules.\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Camera settings\n",
    "cap = cv2.VideoCapture(0) \n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cap.set(cv2.CAP_PROP_FPS, 24)\n",
    "\n",
    "# Window size\n",
    "window_width, window_height = 1024, 720\n",
    "\n",
    "DATASET_PATH = 'DATASET'\n",
    "actions = np.array(os.listdir(DATASET_PATH))\n",
    "model = load_model('sonuclar/CNN+GRU_best_model2.keras', compile=False)\n",
    "\n",
    "sentence, keypoints, last_prediction = [], [], []\n",
    "\n",
    "# Font settings (Turkish character support)\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 32)\n",
    "except:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.7, min_tracking_confidence=0.7) as holistic:\n",
    "    while ret:\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = holistic.process(image)\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            left_shoulder = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER]\n",
    "            right_shoulder = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER]\n",
    "\n",
    "            x_center = int(((left_shoulder.x + right_shoulder.x) / 2) * frame_width)\n",
    "            y_center = int(((left_shoulder.y + right_shoulder.y) / 2) * frame_height)\n",
    "\n",
    "            start_x = max(x_center - window_width // 2, 0)\n",
    "            end_x = start_x + window_width\n",
    "            if end_x > frame_width:\n",
    "                end_x = frame_width\n",
    "                start_x = frame_width - window_width\n",
    "\n",
    "            start_y = max(y_center - window_height // 2, 0)\n",
    "            end_y = start_y + window_height\n",
    "            if end_y > frame_height:\n",
    "                end_y = frame_height\n",
    "                start_y = frame_height - window_height\n",
    "\n",
    "            window = frame[start_y:end_y, start_x:end_x]\n",
    "\n",
    "            # Extract the landmarks.\n",
    "            pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33 * 4)\n",
    "            face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468 * 3)\n",
    "            lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21 * 3)\n",
    "            rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21 * 3)\n",
    "\n",
    "            res_all = np.concatenate([pose, face, lh, rh])\n",
    "\n",
    "            indices_to_remove = np.r_[92:1536]\n",
    "            filtered_keypoints = np.delete(res_all, indices_to_remove)\n",
    "            keypoints.append(filtered_keypoints)\n",
    "\n",
    "            # Drawing on the image\n",
    "            window = cv2.flip(window, 1)\n",
    "            pil_image = Image.fromarray(cv2.cvtColor(window, cv2.COLOR_BGR2RGB))\n",
    "            draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "            # Show the frame count to the user\n",
    "            if len(keypoints) < 30:\n",
    "                progress_text = f\"Veri Toplanıyor: {len(keypoints)}/30\"\n",
    "                draw.text((50, window.shape[0] - 50), progress_text, font=font, fill=(255, 0, 0))\n",
    "\n",
    "            # Make a prediction after 30 frames.\n",
    "            if len(keypoints) == 30:\n",
    "                keypoints_np = np.array(keypoints)\n",
    "                prediction = model.predict(keypoints_np[np.newaxis, :, :])\n",
    "                keypoints = []\n",
    "\n",
    "                top3_indices = prediction[0].argsort()[-3:][::-1]\n",
    "                top3_labels_scores = [(actions[i], prediction[0][i]) for i in top3_indices]\n",
    "\n",
    "                top_label = actions[top3_indices[0]]\n",
    "                top_score = prediction[0][top3_indices[0]]\n",
    "\n",
    "                if top_score > 0.7:\n",
    "                    if last_prediction != top_label:\n",
    "                        sentence.append(top_label)\n",
    "                        last_prediction = top_label\n",
    "                        time.sleep(4.0)\n",
    "\n",
    "            # Limit the sentence length\n",
    "            if len(sentence) > 7:\n",
    "                sentence = sentence[-7:]\n",
    "\n",
    "            # Write the centered sentence.\n",
    "            text = ' '.join(sentence)\n",
    "            text_bbox = draw.textbbox((0, 0), text, font=font)\n",
    "            text_width = text_bbox[2] - text_bbox[0]\n",
    "            text_x = (window.shape[1] - text_width) // 2\n",
    "            draw.text((text_x, 650), text, font=font, fill=(255, 255, 255))\n",
    "\n",
    "            # Write the top 3 predictions in the top-left corner.\n",
    "            if 'top3_labels_scores' in locals():\n",
    "                y_offset = 20\n",
    "                for label, score in top3_labels_scores:\n",
    "                    color = (0, 200, 0) if score > 0.7 else (255, 165, 0) if score > 0.4 else (180, 180, 180)\n",
    "                    draw.text((30, y_offset), f\"{label}: {score:.2f}\", font=font, fill=color)\n",
    "                    y_offset += 40\n",
    "\n",
    "            # Display the image.\n",
    "            window = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "            cv2.imshow('Turkce Isaret Dili Tanıma', window)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
